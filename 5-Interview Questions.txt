1.linux命令：
    ① load average后面三个数字分别代表不同时间段即一分钟、五分钟和十五分钟的系统平均负载；
    ② cat /proc/loadavg 第四个值的分子是正在运行的进程数，分母为总进程数；第五个值是最近运行的进程id；
    ③ ps aux --sort -rss 查看应用内存的使用情况；

2.ExecutorService ThreadPool →  动态维护线程池，什么场景下适合。
     newFixedThreadPool： LinkedBlockingQueue   
     newSingleThreadExecutor：LinkedBlockingQueue 
     newCachedThreadPool：SynchronousQueue

3.研究代码的时候最好看看源码，深入了解下原理

4.mysql的隔离级别，各自优缺点
   事务的基本要素（ACID）
　　 原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，
   会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。
　　 一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。
　　 隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，
   在A取钱的过程结束前，B不能向这张卡转账。
　　 持久性（Durability）：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。

   事务隔离级别                                   脏读       不可重复读       幻读 
     读未提交（read-uncommitted）                 Y              Y             Y 
     不可重复读（read-committed）		  N              Y             Y 
     可重复读（repeatable-read）		  N              N             Y 
     串行化（serializable）                       N              N             N 

    脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据
　　不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致。
　　幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，
  当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。
　　小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，
  解决幻读需要锁表

5.基本数据类型和引用数据类型的区别
   区别:基本数据类型和引用类型的区别主要在于基本数据类型是分配在栈上的，而引用类型是分配在堆上的（需要java中的栈、堆概念），
   猜想：不论是基本数据类型还是引用类型，他们都会先在栈中分配一块内存，对于基本类型来说，这块区域包含的是基本类型的内容；
   而对于对象类型来说，这块区域包含的是指向真正内容的指针，真正的内容被手动的分配在堆上。

6.mysql 索引方式，深入研究，建立索引，在where条件是否生效原理，深入研究； 总体规则就是就近生效原则：
  复合索引顺序：idx_table_name_object_table_name  
      存在断路原则，索引的先后顺序，a b c 如果where 后面没有 a ，则不生效，只要有就行，跟顺序没关系；加上or 都失效，除非每个都建立索引；
    ① 这种情况失效：EXPLAIN SELECT * FROM user_sub_table WHERE table_name LIKE '%user' 
    ② 这种情况失效：EXPLAIN SELECT * FROM user_sub_table WHERE object_table_name LIKE '%aa' AND  table_name LIKE '%user'  
      这种情况生效：EXPLAIN SELECT * FROM user_sub_table WHERE object_table_name LIKE '%aa' AND  table_name LIKE 'user%'  
      这种情况生效：EXPLAIN SELECT * FROM user_sub_table WHERE object_table_name LIKE 'aa%' AND  table_name LIKE 'user%'  
      这种情况失效：EXPLAIN SELECT * FROM user_sub_table WHERE object_table_name LIKE 'aa%' AND  table_name LIKE '%user'  
      这种情况失效：EXPLAIN SELECT * FROM user_sub_table WHERE object_table_name = 'aa%' OR  table_name = 'user%' 

      这种情况生效：EXPLAIN SELECT * FROM user_sub_table WHERE table_name = 'aa' AND  object_table_name = 'user'  
      这种情况生效：EXPLAIN SELECT * FROM user_sub_table WHERE object_table_name = 'aa' AND table_name  = 'user'  

  单键索引：idx_table_name/idx_object_table_name    总体规则就是就近生效原则：
    ①【idx_object_table_name】 EXPLAIN SELECT * FROM user_sub_table WHERE object_table_name LIKE 'aa%'   AND table_name  LIKE 'user%'   
    ②                          EXPLAIN SELECT * FROM user_sub_table WHERE object_table_name LIKE '%aa'   AND table_name  LIKE '%user'  
    ③ 【idx_object_table_name】 EXPLAIN SELECT * FROM user_sub_table WHERE object_table_name LIKE 'aa%'   AND table_name  LIKE '%user'  
    ④ 【idx_table_name】      EXPLAIN SELECT * FROM user_sub_table WHERE object_table_name LIKE '%aa'   AND table_name  LIKE 'user%' 
    ⑤                         EXPLAIN SELECT * FROM user_sub_table WHERE object_table_name LIKE 'aa%' OR table_name  LIKE 'user%'  

    ⑥【table_name】        EXPLAIN SELECT * FROM user_sub_table WHERE table_name = 'aa' AND  object_table_name = 'user'  
    ⑦【object_table_name】 EXPLAIN SELECT * FROM user_sub_table WHERE object_table_name = 'aa' AND table_name  = 'user'  
    ⑧【null】              EXPLAIN SELECT * FROM user_sub_table WHERE object_table_name = 'aa' OR table_name  = 'user'  
    如果出现=号，like也满足条件，那么=号的索引生效
    ⑨【idx_table_name】    EXPLAIN SELECT * FROM user_sub_table WHERE object_table_name LIKE 'aa%' AND table_name  = '%user' 

7.Synchronized 和 ReentrantLock 的区别  深入研究；轮训，可重入，中断，可以设置超时时间，如果超时会回到等待池。
      ReentrantLock实现原理
     参照代码：\crudreposity实现读写分离和Redis处理（经典）\crudreposity\src\main\java\datacenter\crudreposity\aspect\LockAspect.java
  Condition的使用：参照：https://www.cnblogs.com/hongdada/p/6150699.html
      问题出现在当缓冲区已经满了，而此时生产者还想向其中放入一个新的数据项的情形，其解决方法是让生产者此时进行休眠，等待消费者从缓冲区中取走
      了一个或者多个数据后再去唤醒它。
      同样地，当缓冲区已经空了，而消费者还想去取消息，此时也可以让消费者进行休眠，等待生产者放入一个或者多个数据时再唤醒它。
      Condition 将 Object 监视器方法（wait、notify 和 notifyAll）分解成截然不同的对象，以便通过将这些对象与任意 Lock 实现组合使用，为每个对
      象提供多个等待 set （wait-set）。
      其中，Lock 替代了 synchronized 方法和语句的使用，Condition 替代了 Object 监视器方法的使用。
      在Condition中，用await()替换wait()，用signal()替换notify()，用signalAll()替换notifyAll()，传统线程的通信方式，Condition都可以实现，
      这里注意，Condition是被绑定到Lock上的，要创建一个Lock的Condition必须用newCondition()方法。



8.list 和 set 的区别，隐身其他集合的深入研究
        //list  有序连续的可重复数组，读取快，写入慢；

        //set的用法:无序且不能存储相同的元素，读取慢，写入快； https://blog.csdn.net/Dzy_water/article/details/79144206
        //TreeSet         :会将里面的元素默认排序。TreeSet(内部实现二叉树) 主要作用:排序 Comparable，Comparator，compareTo
        //Hashset         :它是无顺序的，利用hash算法给赋值,使用HashSet 主要用来去重,当Set集合在进行存储的时候,hashCode值相同时,
        // 会调用equals方法进行对比是同一个对象就不存;当hashCode值不相同时 不用调用equals方法,可以直接存
        //LinkedHashSet   :有序 怎么存就怎么取出来

	//        看到array，就要想到角标。
	//        看到link，就要想到first，last。
	//        看到hash，就要想到hashCode,equals.
	//        看到tree，就要想到两个接口。Comparable，Comparator
  

9.多线程原理以及应用场景  深入研究  线程重入，重排序等深入研究 Synchronized和Volatile区别，各自深入研究  看视频
  synchronized和volatile都可以禁止重排序，指令重排序在虚拟机层面，为了尽可能减少内存操作速度远慢于CPU运行速度所带来的CPU空置的影响，
  虚拟机会按照自己的一些规则将程序编写顺序打乱——即写在后面的代码在时间顺序上可能会先执行，而写在前面的代码会后执行——以尽可能充分地利用CPU。
  线程中断规则(Thread Interruption Rule)：对线程interrupte()方法的调用优先于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()
  方法检测线程是否已中断。
  volatile可以保证线程可见性且提供了一定的有序性，但是无法保证原子性。在JVM底层volatile是采用 “内存屏障” 来实现的。
      当一个变量被volatile修饰后，表示着线程本地内存无效，当一个线程修改共享变量后他会立即被更新到主内存中，当其他线程读取共享变量时，它会直接
      从主内存中读取。当然，synchronize和锁都可以保证可见性。
      保证可见性、有序性、不保证原子性
      禁止指令重排序
    ① 对变量的写操作不依赖当前值；
    ② 该变量没有包含在具有其他变量的不变式中。
       volatile经常用于两个两个场景：状态标记两、double check
10.分库分表怎么分，深入研究？
   分表→ 按时间分：建立一个字典表，把表的配置写入
         比如：id、表名、开始时间、结束时间、要写入的表名
	 user  user_1  user_2  写一个存储过程根据当前系统时间判断需要插入到哪个表
	 然后插入或者更新就可以了。以后查询也是按照这个规则来。
	 配置表：CREATE TABLE `user_sub_table` (
	  `id` bigint(20) NOT NULL AUTO_INCREMENT,
	  `table_name` varchar(20) DEFAULT NULL,
	  `start_time` datetime DEFAULT NULL,
	  `end_time` datetime DEFAULT NULL,
	  `object_table_name` varchar(20) DEFAULT NULL,
	  PRIMARY KEY (`id`)
	) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=latin1

	id     `table_name`  `start_time`             `end_time`             `object_table_name`
	"1	  user	   2018-11-13 16:57:55	   2018-11-15 16:58:06	          user_1"
	"2	  user	   2018-11-16 16:58:19	   2018-11-17 16:58:27	          user_2"

   分库→ 

11.int 和 Integer的区别

12.hashtable
   Hashtable<String, Integer> table = new Hashtable<String, Integer>();
   ① Hashtable 是一个散列表，它存储的内容是键值对(key-value)映射。
   ② Hashtable 继承于Dictionary，实现了Map、Cloneable、java.io.Serializable接口。
   ③ Hashtable 的函数都是同步的，这意味着它是线程安全的。它的key、value都不可以为null

结论：HashMap对象的key、value值均可为null。它不是线程安全的。           
      HahTable对象的key、value值均不可为null。
      且两者的的key值均不能重复，若添加key相同的键值对，后面的value会自动覆盖前面的value，但不会报错。

13.聚集索引和非聚集索引   mysql2大索引类型（B-tree索引和hash索引）
   每个表只能有一个聚簇索引，因为一个表中的记录只能以一种物理顺序存放。但是，一个表可以有不止一个非聚簇索引。实际上
   ，对每个表你最多可以建立249个非聚簇索引。非聚簇索引需要大量的硬盘空间和内存。另外，虽然非聚簇索引可以提高从表中
   取数据的速度，它也会降低向表中插入和更新数据的速度。每当你改变了一个建立了非聚簇索引的表中的数据时，必须同时更新索引。
   因此你对一个表建立非聚簇索引时要慎重考虑。如果你预计一个表需要频繁地更新数据，那么不要对它建立太多非聚簇索引。
   另外，如果硬盘和内存空间有限，也应该限制使用非聚簇索引的数量。
    聚簇索引的侯选列
   ①、主键列,该列在where子句中使用并且插入是随机的。
   ②、按范围存取的列，如pri_order > 100 and pri_order < 200。
   ③、在group by或order by中使用的列。
   ④、不经常修改的列。
   ⑤、在连接操作中使用的列。
 
14.aop基于spring什么原理实现的？spring原理？集群如果数据没实时同步，会导致客户端读取的数据不准确，改怎么保证？
   aop的所谓“方面”，简单地说，就是将那些与业务无关，却为业务模块所共同调用的逻辑或责任封装起来，便于减少系统的重复代码，降低模块间的耦合度，
    并有利于未来的可操作性和可维护性。
    要了解Spring的AOP就必须先了解的动态代理的原理，因为AOP就是基于动态代理实现的。动态代理还要从JDK本身说起。

    APO使用场景：
    Authentication 权限
    Caching 缓存
    Context passing 内容传递
    Error handling 错误处理
    Lazy loading　懒加载
    Debugging　　调试
    logging, tracing, profiling and monitoring　记录跟踪　优化　校准
    Performance optimization　性能优化
    Persistence　　持久化
    Resource pooling　资源池
    Synchronization　同步
    Transactions 事务

   Spring是一个分层的轻量级开源容器框架（java开发基础组件），可以接管web层，业务层，dao层，持久层的组件，并且可以配置各种bean,和维护bean与
   bean之间的关系。
   其核心就是控制反转(IOC),和面向切面(AOP)。spring框架本身也是按照设计模式精心打造。
   核心模块：数据访问/集成、web、aop、工具、消息和测试模块。
   web模块 → spring mvc原理以及流程


15.redis 属于单线程，阻塞式，一个柜台，为何高效？如何分片，核心原理，深入学习？  
   ① 为什么说redis能够快速执行
   (1) 绝大部分请求是纯粹的内存操作（非常快速）
   (2) 采用单线程,避免了不必要的上下文切换和竞争条件
   (3) 非阻塞IO - IO多路复用
   ② redis的内部实现
      内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，
   绝不在io上浪费一点时间 这3个条件不是相互独立的，特别是第一条，如果请求都是耗时的，采用单线程吞吐量及性能可想而知了。应该说redis为
   特殊的场景选择了合适的技术方案。
   ③ Redis关于线程安全问题
     redis实际上是采用了线程封闭的观念，把任务封闭在一个线程，自然避免了线程安全问题，不过对于需要依赖多个redis操作的复合操作来说，依然
     需要锁，而且有可能是分布式锁。
   ④ 运行Sentinel 参照文档：https://www.cnblogs.com/youzhibing/p/8466491.html
   redis-sentinel /path/to/sentinel.conf  or redis-server /path/to/sentinel.conf --sentinel
 
      ※ down-after-milliseconds 对于Sentinel开始认为它已关闭的时间，实例不应该可以到达的时间（无论是不回复我们的PING还是回复错误）都是以毫秒为
         单位的时间。
      ※ parallel-syncs设置可在同一故障转移后重新配置以使用新主服务器的从服务器数。数字越小，故障转移过程完成所需的时间就越多，但是如果从站配置为提
      供旧数据，则可能不希望所有从站同时与主站重新同步。虽然复制过程对于从站主要是非阻塞的，但是有一段时间它停止从主站加载批量数据。您可能希望通过
      将此选项设置为值1来确保一次只能访问一个从站。
		       +----+
			 | M1 |
			 | S1 | <- C1 (writes will be lost)
			 +----+
			    |
			    /
			    /
		+------+    |    +----+
		| [M2] |----+----| R3 |
		| S2   |         | S3 |
		+------+         +----+
	   在这种情况下，网络分区隔离了旧的主M1，因此从属R2被提升为主。但是，与旧主服务器位于同一分区中的客户端（如C1）可能会继续将数据写入
	旧主服务器.这个数据将永远丢失，因为当分区将愈合时，主机将被重新配置为新主机的从机，丢弃其数据集。
	使用以下Redis复制功能可以缓解此问题，如果主服务器检测到不再能够将其写入传输到指定数量的从服务器，则允许停止接受写入。
	min-slaves配置选项
	     min-slaves-to-write 1  //从节点数量少于1个，主节点拒绝执行写命令
	     min-slaves-max-lag 10  //1个从节点的延迟(lag)值，大于或等于10，主节点拒绝执行写命令
	  使用上述配置（请参阅redis.confRedis发行版中的自注释示例以获取更多信息）Redis实例作为主服务器时，如果无法写入至少1个从服务器，将停止接
	受写入。由于复制是异步的，因此无法实际写入意味着从属设备已断开连接，或者未向我们发送超过指定max-lag秒数的异步确认。
	  使用此配置，上例中的旧Redis主M1将在10秒后变为不可用。当分区恢复时，Sentinel配置将收敛到新的配置，客户端C1将能够获取有效配置并继续使用新
	主设备。但是没有免费的午餐。通过这种改进，如果两个从站关闭，主站将停止接受写入。这是一个折衷。

        ※这里需要注意的是：sentinel需要在55和56做好主从之后才能开启，即：在56上执行slaveof，搭建好主从之后，再开启3个sentinel监控服务，一个高可用
	的（主从自动切换）搭建完成。可以通过在master上执行redis-cli -p 6379 DEBUG sleep 30 命令来模拟故障转移，来测试sentinel故障转移是否搭建成
	功：127.0.0.1:5000> SENTINEL get-master-addr-by-name mymaster 用这个命令查看当前master节点信息，看是否自动切换了master.
        如果其中的一个从挂了，那么重启这个从之后，数据会自动同步到该从。
    总体部署: 可以参照 → https://blog.csdn.net/guying4875/article/details/79045075
   4、java jedis客户端配置： 如果想读取从节点，用Nginx做负载均衡,可以配置Nginx节点ip和端口...
        redis.masterName=mymaster
	redis.sentinels=192.168.11.202:26379,192.168.11.202:26380,192.168.11.202:26381
	redis.timeout=10000
	#连接master需要用到的密码，如果redis数据节点开启了连接认证
	redis.password=myredis
    ① 有人可能会有这样的疑问：为什么通过sentinel来获取redis的连接，而不是直接连接master来获取redis连接呢？
　　　　试想一下，客户端直接通过master节点获取redis连接，如果master节点挂掉了，虽然Redis Sentinel可以完成故障转移，但是客户端无法获取这个变化，
      那么客户端就无法获取redis连接了；
　　　　最了解master节点信息的就是Sentinel节点集合，所以通过sentinel来获取redis连接就能满足高可用的要求了。
　　 ② redis master的故障转移不影响客户端连接代码， 但是转移期间内，通过sentinel是获取不到主节点的连接的， 因为转移期间内master节点还没被选举出
   来；
	
16.mongodb 属于多线程，非阻塞，多个柜台，核心原理，深入学习？
   ① 为什么要分片
     随着数据量的增长，要在一块磁盘或者一组RAID阵列上保存和管理备份如此大规模的数据集也变得不太现实。如果还想继续使用普通硬件或者虚拟硬件来托管
     数据库，那么这对这类问题的解决方案就是将数据库分布到多台服务器上，这种方法称之为分片。
   ② 什么是MongoDB ?
     MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。
     在高负载的情况下，添加更多的节点，可以保证服务器性能。
     MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。
     MongoDB 将数据存储为一个文档，数据结构由键值(key=>value)对组成。MongoDB 文档类似于 JSON 对象
   ③ 主要特点
     MongoDB的提供了一个面向文档存储，操作起来比较简单和容易。
     你可以在MongoDB记录中设置任何属性的索引 (如：FirstName="Sameer",Address="8 Gandhi Road")来实现更快的排序。
     你可以通过本地或者网络创建数据镜像，这使得MongoDB有更强的扩展性。
     如果负载的增加（需要更多的存储空间和更强的处理能力） ，它可以分布在计算机网络中的其他节点上这就是所谓的分片。
     Mongo支持丰富的查询表达式。查询指令使用JSON形式的标记，可轻易查询文档中内嵌的对象及数组。
     MongoDb 使用update()命令可以实现替换完成的文档（数据）或者一些指定的数据字段 。
     Mongodb中的Map/reduce主要是用来对数据进行批量处理和聚合操作。
     Map和Reduce。Map函数调用emit(key,value)遍历集合中所有的记录，将key与value传给Reduce函数进行处理。
     Map函数和Reduce函数是使用Javascript编写的，并可以通过db.runCommand或mapreduce命令来执行MapReduce操作。
     GridFS是MongoDB中的一个内置功能，可以用于存放大量小文件。
     MongoDB允许在服务端执行脚本，可以用Javascript编写某个函数，直接在服务端执行，也可以把函数的定义存储在服务端，下次直接调用即可。
     MongoDB支持各种编程语言:RUBY，PYTHON，JAVA，C++，PHP，C#等多种语言。
   ④ 首先.mongodb怎样使用内存
     mongodb使用内存映射存储引擎，
     它会把数据文件映射到内存中，如果是读操作，内存中的数据起到缓存的作用，如果是写操作，内存还可以把随机的写操作转换成顺序的写操作，总之可以大幅
     度提升性能;
     MongoDB并不干涉内存管理工作，而是把这些工作留给操作系统的虚拟内存管理器去处理，这样做的好处是简化了MongoDB的工作，但坏处是你没有方法很方便的
     控制MongoDB;
     占多大内存，幸运的是虚拟内存管理器的存在让我们多数时候并不需要关心这个问题;
     MongoDB的内存使用机制让它在缓存重建方面更有优势，简而言之：如果重启进程，那么缓存依然有效，如果重启系统，那么可以通过拷贝数据文件到/dev/null
     的方式来重建缓存;
   ⑤ mongo使用场合
     mongodb的主要目标是在键/值存储方式（提供了高性能和高度伸缩性）以及传统的RDBMS系统（丰富的功能）架起一座桥梁，集两者的优势于一身。
     mongo适用于以下场景：
     网站数据：mongo非常适合实时的插入，更新与查询，并具备网站实时数据存储所需的复制及高度伸缩性。
     缓存：由于性能很高，mongo也适合作为信息基础设施的缓存层。在系统重启之后，由mongo搭建的持久化缓存可以避免下层的数据源过载。
     大尺寸、低价值的数据：使用传统的关系数据库存储一些数据时可能会比较贵，在此之前，很多程序员往往会选择传统的文件进行存储。
     高伸缩性的场景：mongo非常适合由数十或者数百台服务器组成的数据库。
     用于对象及JSON数据的存储：mongo的BSON数据格式非常适合文档格式化的存储及查询。
   ⑥ 不适合的场景：
     高度事物性的系统：例如银行或会计系统。传统的关系型数据库目前还是更适用于需要大量原子性复杂事务的应用程序。
     传统的商业智能应用：针对特定问题的BI数据库会对产生高度优化的查询方式。对于此类应用，数据仓库可能是更合适的选择。
     需要SQL的问题。
  
17.java GC1原理 之前的是CMS UseConcMarkSeepGC 原理

18.java 单向链表反转  实现

19.分库分表  分表的思想 → 数据量大的情况：可以存储上ES/lucence上，供查询用，这个想法很好！
                          数据量小的情况：通过配置表按时间拆分；

20. redis分片(partitioning)就是将你的数据拆分到多个 Redis 实例的过程，这样每个实例将只包含所有键的子集。
    分片能做什么
	Redis 的分片承担着两个主要目标：
	允许使用很多电脑的内存总和来支持更大的数据库。没有分片，你就被局限于单机能支持的内存容量。
	允许伸缩计算能力到多核或多服务器，伸缩网络带宽到多服务器或多网络适配器。
    分片的不同实现
	分片可由软件栈中的不同部分来承担。
	    客户端分片(Client side partitioning)意味着，客户端直接选择正确的节点来写入和读取指定键。许多 Redis 客户端实现了客户端分片。
	    代理协助分片(Proxy assisted partitioning)意味着，我们的客户端发送请求到一个可以理解 Redis 协议的代理上，而不是直接发送请求到 Redis  
	 实例上。代理会根据配置好的分片模式，来保证转发我们的请求到正确的 Redis 实例，并返回响应给客户端。Redis 和 Memcached 的代理 Twemproxy 
	 实现了代理协助的分片。
	    查询路由(Query routing)意味着，你可以发送你的查询到一个随机实例，这个实例会保证转发你的查询到正确的节点。Redis 集群在客户端的帮助下， 
	 实现了查询路由的一种混合形式 (请求不是直接从 Redis 实例转发到另一个，而是客户端收到重定向到正确的节点)。

21.ThreadLocal 
　　ThreadLocal一般称为线程本地变量，它是一种特殊的线程绑定机制，将变量与线程绑定在一起，为每一个线程维护一个独立的变量副本。通过ThreadLocal
    可以将对象的可见范围限制在同一个线程内。

22-1.synchronize实现原理   回去搜索各种原理，熟练掌握
   每个对象有一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：
	①、如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。
	②、如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1.
	③.如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。
  执行monitorexit的线程必须是objectref所对应的monitor的所有者。
  指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取
  这个 monitor 的所有权。 
  通过这两段描述，我们应该能很清楚的看出Synchronized的实现原理，Synchronized的语义底层是通过一个monitor的对象来完成，其实wait/notify等方法也
  依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。

23.hashmap在1.8中的性能提升在哪里，如何提升的

24.springmvc流程 ioc原理以及生命周期？  https://blog.csdn.net/javaxuexi123/article/details/80804800

25.gc步骤和原理

26.spring 哪些功能用模板方法，工厂，策略，责任链模式  https://www.cnblogs.com/baizhanshi/p/6187537.html
   ①工厂模式    ApplicationContext →派生出ConfigurableApplicationContext 应用上下文初始器
                在使用Spring的时候，我们经常需要先得到一个ApplicationContext对象，然后从该对象中获取我们配置的Bean对象。
                ApplicationContext隶属于org.springframework.context，是SpringFramework中Bean的管理者，为SpringFramework的诸多功能提供支撑作用。

   ②观察者模式 事件传播机制  ApplicationListener监听ApplicationEvent事件，一旦spring bean 使用 ApplicationContext.publishEvent
                (ApplicationEvent event)发布事件后，Spring 容器会通知注册在 bean.xml 中所有 ApplicationListener 接口的实现类，最后 ApplicationListener 
                接口实现类判断是否响应刚发布出来的 ApplicationEvent 事件。

   ③模板方法模式 1.AbstractApplicationContext 实现了ApplicationContext 接口中简单不易变动的部分，然后通过“组合”将众多“容易变动”功能代理给它的一些成员变
                   量来实现，最后再使用模板方法模式让子类为父类提供一些函数的支持或者设置替换父类的上述成员变量，从而实现了“对扩展开放，对修改封闭”的
		   设计原则，为Spring Framework 提供了灵活性大可扩展性强的架构支撑。
		 2.还有集合CopyOnWriteArraySet<> 继承了AbstractSet → AbstractCollection<E>
                 3.Servlet容器 DispatcherServlet → 继承FrameworkServlet → 继承HttpServletBean → 继承httpServlet 

   ④策略模式     视图 → 内容协商策略实现 ContentNegotiationStrategy

   ⑤责任链模式   Filter实现 → 初始化：Filter#init(FilerConfig) → 过滤：Filter#doFilter(FilterChain,ServletRequest,ServletResponse) → 
                 Filter#destory()

27.spring cloud注册发现的原理    Spring Cloud之Eureka服务注册与发现（概念原理篇）https://www.jianshu.com/p/2fa691d4a00a
                                 eureka的server和client各种配置https://www.jianshu.com/p/98f4e5f6bca7

28.jstack Dump 日志文件中的线程状态（重点看死循环和死锁的状态）
	①：dump 文件里，值得关注的线程状态有
		死锁， Deadlock（重点关注） 
		执行中，Runnable   
		等待资源， Waiting on condition（重点关注） 
		等待获取监视器， Waiting on monitor entry（重点关注）
		暂停，Suspended
		对象等待中，Object.wait() 或 TIMED_WAITING
		阻塞， Blocked（重点关注）  
		停止，Parked
	②：Dump文件中的线程状态含义及注意事项
	Deadlock：死锁线程，一般指多个线程调用间，进入相互资源占用，导致一直等待无法释放的情况。
	Runnable：一般指该线程正在执行状态中，该线程占用了资源，正在处理某个请求，有可能正在传递SQL到数据库执行，有可能在对某个文件操作，有
	          可能进行数据类型等转换。
	Waiting on condition：该状态出现在线程等待某个条件的发生。具体是什么原因，可以结合 stacktrace来分析。最常见的情况是线程在等待网络的
	          读写，比如当网络数据没有准备好读时，线程处于这种等待状态，而一旦有数据准备好读之后，线程会重新激活，读取并处理数据。在 Java
		  引入 NewIO之前，对于每个网络连接，都有一个对应的线程来处理网络的读写操作，即使没有可读写的数据，线程仍然阻塞在读写操作上，这
		  样有可能造成资源浪费，而且给操作系统的线程调度也带来压力。在 NewIO里采用了新的机制，编写的服务器程序的性能和可扩展性都得到提高。
		如果发现有大量的线程都在处在 Wait on condition，从线程 stack看， 正等待网络读写，这可能是一个网络瓶颈的征兆。因为网络阻塞导致线
		程无法执行。一种情况是网络非常忙，几 乎消耗了所有的带宽，仍然有大量数据等待网络读 写；另一种情况也可能是网络空闲，但由于路由等问
		题，导致包无法正常的到达。所以要结合系统的一些性能观察工具来综合分析，比如 netstat统计单位时间的发送包的数目，如果很明显超过了所
		在网络带宽的限制 ; 观察 cpu的利用率，如果系统态的 CPU时间，相对于用户态的 CPU时间比例较高；如果程序运行在 Solaris 10平台上，可以
		用 dtrace工具看系统调用的情况，如果观察到 read/write的系统调用的次数或者运行时间遥遥领先；这些都指向由于网络带宽所限导致的网络瓶颈
		。另外一种出现 Wait on condition的常见情况是该线程在 sleep，等待 sleep的时间到了时候，将被唤醒。
	Blocked：线程阻塞，是指当前线程执行过程中，所需要的资源长时间等待却一直未能获取到，被容器的线程管理器标识为阻塞状态，可以理解为等待资源
	超时的线程。
	Waiting for monitor entry 和 in Object.wait()：Monitor是 Java中用以实现线程之间的互斥与协作的主要手段，它可以看成是对象或者 Class的锁。
	每一个对象都有，也仅有一个 monitor。

29.synchronized 修饰带staitc 方法、变量和修饰不带static 方法、变量 有啥区别？
   修饰带static的，由于是类方法和类变量，那么在锁控制的时候是同一个方法和对象，能达到锁的目的，
   如果修饰不带static的，那么每次调用会new 出一个对象，调用方法，导致每次new都是一个新对象，那么所机制就失效了。

30.Aspect切面编程 可以指定执行顺序。例如：用注解的方式 → 参照项目：datacenter/crudreposity/aspect/AuthorizeAspect.java
	@Aspect
	@Component
	@Order(2)
   注意：如果以后项目用到 @Around("lockAspect"),那么不能再添加此注解的方法内抛出异常（ControllerAdvice捕捉不到，具体原因是 @Around()没有执行完成
    ，所以捕捉不到，程序终止了），具体做法是让此方法返回错误信息给
   @Around(),在 @Around() 里面抛出异常即可。






